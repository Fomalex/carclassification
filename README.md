Приветствую! 
В процессе выполнения проекта "Ford vs Ferrari: определяем модель авто по фото" было создано достаточно много версий ноутбуков на kaggle, но для 
демонстрации результатов в данном репозитории привожу только две:
  1). fork-of-keras-efficientnet-car-class.ipynb - score: 0.93752 - В данном ноутбуке я взял в качестве базовой модели EfficientNetB5 и попробовал применить 
transfer learning с fine-tuning, также добавил BatchNormalization на выходе модели.
  2). baseline-keras-xception-car-class-v2-0-b434a6.ipynb - score: 0.96209 - В данном ноутбуке я взял в качестве базовой модели EfficientNetB6, изменил подаваемый на вход размер картинки, кол-во эпох обучения, batchsize, в архитектуре "головы" изменил полносвязный слой, не добавлял по сравнению с предыдущим ноутбуком BatchNormalization, а также добавил Test Time Augmentation и обучал всю модель на 100% train, не разделяя на 85% train и 15% validation.
  В процессе поиска лучшего решения для улучшения score на kaggle пробовал "подкручивать" параметры аугментации данных, а именно horizontal_flip, vertical_flip, rotation_range, width_shift_range, height_shift_range, brightness_range, shear_range, zoom_range, но всё приводило к ухудшению сходимости модели :(
  Помимо этого, экспериментировал с уменьшением/увеличением learning rate и изменением количества эпох, но оптимумом выбрал параметры, недалеко отходящие от базового решения (опять же на основе полученного скора на kaggle). 
  Достигнутым результатом не до конца доволен, т.к. планирую в дальнейшем настроить оптимальные параметры lr и epochs для transfer learning с fine-tuning, а также найти те параметры аугментации (скорее всего в других библиотеках), которые смогут сильнее улучшить качество модели.
  Буду благодарен за разбор и "подталкивание" в нужную сторону :)
  
С уважением, 
Фомичев Александр
